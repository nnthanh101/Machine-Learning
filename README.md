# ğŸ”¥ MLOps at Scale ğŸ¦…

ğŸŒŸ An end-to-end full-stack Data Science and AI/ML project effectively implementing ML models, MLOps practices, scalable machine learning, and data storytelling. âœ¨


ğŸ“š `ğŸ› ï¸ Experiment (Design + Develop) --> ğŸš€ Production (Deploy + Iterate) âš™ï¸`: Full-Stack **Data Science** and Production-Grade **Machine Learning** at Scale are the fastest-growing fields in technology. This repository aims to develop professional and strong advanced analytics skills to compete in the age of digital and AI. ğŸ

<div align="left">
  <a href="https://www.linkedin.com/in/nnthanh" target="blank"><img align="center" src="https://img.shields.io/badge/-nnthanh-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/nnthanh/" alt="Nhat-Thanh Nguyen" height="25" width="100" /></a>
  <a href="https://github.com/nnthanh101/" target="blank"><img align="center" src="https://img.shields.io/github/followers/nnthanh101?label=Follow&style=social&link=https://github.com/nnthanh101/" alt="Thanh Nguyen" height="25" width="100" /></a>
  <a href="https://www.facebook.com/groups/platformengineering" target="blank"><img align="center" src="https://img.shields.io/badge/Facebook-blue?style=flat-square&logo=facebook&logoColor=white&link=[https://www.linkedin.com/in/nnthanh/](https://www.facebook.com/groups/platformengineering)" alt="Nhat-Thanh Nguyen" height="25" width="100" /></a>  
</div>

---

ğŸ¯ End-to-end full-stack machine learning from experimental (design + development) to production (deployment + iteration) for iteratively building reliable production-grade AI/ML applications.

* [x] ğŸ’¡ Agile CRISP-DM for Data Science and Machine Learning
  * [x] Cookiecutter Data Science (CCDS) V2: data science tooling and MLOps
  * [x] Agile Implementation of CRISP-DM for Data Science and Machine Learning
* [ ] âš™ï¸ MLOps
  * [ ] ğŸ’» DevOps best practices for developing and deploying machine learning models.
  * [ ] âš™ï¸Â BuildÂ anÂ end-to-end machineÂ learningÂ systemÂ byÂ connectingÂ MLOpsÂ componentsÂ suchÂ asÂ tracking,Â testing,Â serving,Â andÂ orchestration.
* [ ] ğŸš€ Dev to Prod:
  * [ ] ğŸ™ Develop robust CI/CD workflows to continuously train and deploy better models in a modular way that integrates with any stack.
  * [ ] ğŸ“ˆ Scale: ML workloads (data, training, tuning, and serving) are easily scalable, facilitating a quick and reliable transition from development to production without requiring code or infrastructure modifications.

---

## Deliverables ğŸ’

|**:calendar:**|**:alarm_clock: Deliverables / Tasks Done**| **:link: Reference Links**|
|------|--------------------|---------------------|
|~~01~~| ğŸ“ **AWS Certified Data Analytics - Specialty (DAS)** (Collecting Streaming Data, Data Collection and Getting Data, Amazon Elastic Map Reduce (EMR), Using Redshift & Redshift Maintenance & Operations, AWS Glue, Athena, and QuickSight, ElasticSearch, AWS Security Services) âœ… | [A Cloud Guru - DAS](https://learn.acloud.guru/course/aws-certified-database-speciality-dbs-c01/dashboard) & [ACG Practice Exam](https://practice-exam.acloud.guru/9f55ebb2-12f8-4a55-a41b-fe5cb1917e30) & [UDemy Practice Exam](https://www.udemy.com/course/aws-certified-data-analytics-specialty-practice-exams-amazon/)|
|02| ğŸ“ **AWS Certified Machine Learning - Specialty (MLS-C01)** (Data Preparation, Data Analysis and Visualization, Modeling, Algorithms, Evaluation and Optimization, Implementation and Operations) â˜‘ï¸ | [A Cloud Guru - MLS-C01](https://learn.acloud.guru/course/aws-certified-machine-learning-specialty/dashboard) & [ACG Practice Exam](https://practice-exam.acloud.guru/f87ac9a1-2d47-44f1-8e10-2a8e43959ef5) & [UDemy Practice Exam](https://www.udemy.com/course/aws-certified-machine-learning-specialty-practice-exams-amazon/) |  
|~~03~~| ğŸ›  Reproducible Local Development for Data Science and Machine Learning projects | [Data Science](https://github.com/nnthanh101/Data-Science) | 
|04| ğŸ‘¨â€ğŸ’» **Analytics-Experience Project:** Time Series Forecasting & Machine Learning Prediction | [Analytics-Experience Project](https://analytics-experience.pages.dev) |
|05| ğŸ“š **MLOps** | [MLOps]() |
|06| ğŸ’¹ **Analytics Dashboard:** Data Insights & Visual Analytics | [Visual Analytics]()|
|07| ğŸš€ **Scalable MLOps** MLOps at Production-grade Scale | [Scalable MLOps](#)|

--------

## Project Organization

> ğŸ›  Production-grade project structure for successful data-science or machine-learning projects ğŸš€

```
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          ğŸ¤ Explain your project and its structure for better collaboration.
â”œâ”€â”€ config/
â”‚   â””â”€â”€ logging.config.ini
â”œâ”€â”€ data               ğŸ” Where all your raw and processed data files are stored.
â”‚   â”œâ”€â”€ external       <- Data from third-party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, unprocessed, immutable data dump.
â”‚
â”œâ”€â”€ docs               ğŸ““ A default docusaurus | mkdocs project; see docusaurus.io | mkdocs.org for details
â”‚
â”œâ”€â”€ models             ğŸ§  Store your trained and serialized models for easy access and versioning.
â”‚
â”œâ”€â”€ notebooks          ğŸ’» Jupyter notebooks for exploration and visualization.
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â”œâ”€â”€ data_preprocessing.ipynb
â”‚   â”œâ”€â”€ model_training.ipynb
â”‚   â””â”€â”€ model_evaluation.ipynb
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for analytics
â”‚                         and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            ğŸ“Š Generated analysis (reports, charts, and plots) as HTML, PDF, LaTeX.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   ğŸ›  The requirements file for reproducing the analysis environment, for easy environment setup.
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â”œâ”€â”€ src                ğŸ’¾ Source code for data processing, feature engineering, and model training.
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helper_functions.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_preprocessing.py
â”‚   â”œâ”€â”€ test_feature_engineering.py
â”‚   â””â”€â”€ test_model.py
â”œâ”€â”€ setup.py           ğŸ›  A Python script to make the project installable.
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â””â”€â”€ analytics          ğŸ§© Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py    <- Makes analytics a Python module
    â”‚
    â”œâ”€â”€ data           <- Scripts to download, preprocess, or generate data
    â”‚   â””â”€â”€ make_dataset.py
    â”‚
    â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    â”‚   â””â”€â”€ build_features.py
    â”‚
    â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make predictions.           
    â”‚   â”œâ”€â”€ predict_model.py
    â”‚   â””â”€â”€ train_model.py
    â”‚
    â””â”€â”€ visualization  <- Scripts to create exploratory and results-oriented visualizations
        â””â”€â”€ visualize.py
```